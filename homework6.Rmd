---
title: "Homework6"
author: "Danny Nguyen"
date: "2023-11-29"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

# Question 1 

```{r}
homicide <- read_csv("homicide-data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    city_state = str_c(city, state, sep = ","),
    victim_age = as.numeric(victim_age),
    victim_race = fct(victim_race),
    result = ifelse(disposition == "Closed by arrest", 1, 0)) %>% 
  group_by(city_state)%>% 
  filter(city_state != "Tulsa,AL" & city_state!= "Dallas,TX" & city_state != "Phoenix,AZ" & city_state!="Kansas City,MO")%>% 
  filter(victim_race == "White" | victim_race =="Black") %>%
  select(city_state, result, victim_age, victim_race, victim_sex)

baltimore = homicide %>% 
  filter(city_state == "Baltimore,MD")%>% 
  glm(result ~ victim_age + victim_sex + victim_race, data = ., family =binomial())%>%
  broom::tidy() %>%
  mutate(
    OR = exp(estimate),
    lower_ci = exp(estimate - 1.96 * std.error),
    upper_ci = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(term, estimate, OR, lower_ci,upper_ci ) %>% 
  knitr::kable(digits = 3)

baltimore
```

```{r}
OR = homicide %>% 
  nest(data = -city_state) %>% 
  mutate(
    regression = map(.x = data, ~glm(formula = result ~ victim_age + victim_sex + victim_race, data = .x, family = binomial())),
    results = map(regression, broom::tidy)
  ) %>% 
  select(-data, -regression) %>% 
  unnest(results) %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(
    OR = exp(estimate),
    lower_ci = exp(estimate - 1.96 * std.error),
    upper_ci = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(city_state,OR, lower_ci,upper_ci ) 

OR
```
Comparing male victims to female victims, the adjusted OR is 0.426 suggesting that in Baltimore, MD, the odds of solving a homicide for male victims are 0.426 times the the odds of solving a homicide for female victims controlling for other factors. We are 95% confident that this true OR lies between 0.325 and 0.558. The confidence interval does not include 1 meaning that a statistically significant difference.

```{r}
OR %>% 
  ggplot(aes(x = fct_reorder(city_state, OR), y = OR)) +
  geom_point() + 
  geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci)) + 
  theme(axis.text.x = element_text(angle = 90))+
  labs(
    x = "City",
    y = "Adjusted OR",
    title = "Estimated ORs and CIs"
  )
```

# Question 2 
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

```{r}
fit_model <- lm(tmax ~ tmin + prcp, data = weather_df)

set.seed(123456)

boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}

boot_straps = 
  data_frame(
    strap_number = 1:5000,
    strap_sample = rerun(5000, boot_sample(weather_df))
  )

bootstrap_results = 
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin + prcp, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap_sample, -models) %>% 
  unnest(results) 

log_betas <-  
  bootstrap_results %>%
  group_by(strap_number) %>%
  summarise(log_betas = log(estimate[2] * estimate[3])) %>%
  select(log_betas, strap_number)

bootstrap_results2 <- 
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin + prcp, data = .x) ),
    results = map(models, broom::glance)) %>% 
  select(-strap_sample, -models) %>% 
  unnest(results) 

r_squared <- 
  bootstrap_results2 %>%
  select(r.squared, strap_number)
```

#### Fitting density plot of 2 estimates 
```{r}
ggplot(r_squared, aes(x = r.squared)) + 
  geom_density() +
  labs(title = "R-squared Distribution") +
  theme_minimal()

ggplot(log_betas, aes(x = log_betas)) + 
  geom_density() +
  labs(title = "Distribution of log(Beta1 * Beta2)") +
  theme_minimal()

r_squared1 = r_squared %>%
  summarise(r_squared_sd = sd(r.squared), 
            r_squared_mean = mean(r.squared)) %>%
  pull(r_squared_sd, r_squared_mean)

log_betas1 = log_betas %>% 
  summarise(log_betas_sd = sd(as.numeric(log_betas),na.rm = TRUE),
           log_betas_mean = mean(as.numeric(log_betas), na.rm = TRUE) ) %>%
  pull(log_betas_sd, log_betas_mean) 
```
The r-squared values are normally distributed, as the mean of `0.917` with SD of `0.0136`, meaning a consistent model fit across bootstrap samples. Meanwhile, the distribution for log(B1*B2) is left-skewed with a mean of `-6.116` with SD of `1.164`. 

```{r}
CI_result <- log_betas %>%
  summarize(ci_lower = quantile(log_betas, 0.025, na.rm = TRUE),
            ci_upper = quantile(log_betas, 0.975, na.rm = TRUE))
```
The 95% CI is (`r CI_result$ci_lower`, `r CI_result$ci_upper`)

# Question 3 
```{r}
birthweight <- read_csv("birthweight.csv")

birthweight %>% 
  janitor::clean_names() %>% 
   mutate(babysex = ifelse(babysex == "1", "male","female"),
         malform = ifelse(malform == "0", "absent","present"),
         frace = recode(frace, "1" = "White", "2" = "Black", "3" = "Asian", 
                        "4" = "Puerto Rican", "8" = "Other", "9" = "Unknown"),
         mrace = recode(mrace, "1" = "White", "2" = "Black", 
                        "3" = "Asian", "4" = "Puerto Rican", "8" = "Other")) %>%
   mutate(babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace),
    parity = as.factor(parity),
    pnumlbw = as.factor(pnumlbw),
    pnumsga = as.factor(pnumsga))

skimr::skim(birthweight)
```
As We check the dataset and find that there are no missing data, then we perform series of `mutate()` to get appropriate data types as well as how they should be formatted for the regression analysis. The dataset contains 4342 rows and 20 columns in total. 

```{r}
first_model = lm(bwt ~ ., data = birthweight)
summary(first_model)

step(first_model, direction = 'both')
```
I utilize stepwise selection, and it shows that the best fit model should include: `babysex, bhead, blength, delwt, fincome, gaweeks, menarche, mheight, momage,  mrace, parity, ppwt, smoken`. 

```{r}
better_model = lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken, data = birthweight)
summary(better_model)%>%
  broom::tidy() %>%
  select(term, estimate, p.value)

summary(better_model)%>%
  broom::glance()
```
We can see that all variables have significant p-values (<0.05). At the same time, the chosen model has the adjusted r-squared of 0.710 explaining that 71.0% variability in birthweight can be explained by these variables.  All variables are highly significant with strong associations to birthweight.

```{r}
birthweight %>% 
  modelr::add_residuals(first_model) %>%
  modelr::add_predictions(better_model) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = 0.3) +
  labs(
    title = "Residuals vs Chosen Fitted Plot for Birthweight Model",
    x = "Fiited values",
    y = "Residuals"
    ) +
  theme(plot.title = element_text(hjust = 0.5))+
  geom_line(aes(y = 0), color = "blue")

```
The “Residuals vs Chosen Fitted Plot for Birthweight Model” indicates that the residuals are randomly distributed around the horizontal line at 0.

```{r}
model1 = lm(bwt ~ blength + gaweeks, data = birthweight)

model2 = lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex + bhead * blength * babysex, data = birthweight)
```

```{r}
set.seed(234567)

cross_validation = 
  modelr::crossv_mc(birthweight, 100)
  

cv = cross_validation %>%
   mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df <- 
  cross_validation %>%
   mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df <-
  cv_df %>%
    mutate(
    my_model= map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken, data = .x)),
    model_length_gaweeks = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    model_interactions  = map(train, ~lm(bwt ~ (bhead + blength + babysex)^3, data = .x))
    ) %>%
   mutate(
    rmse_my_model = map2_dbl(my_model, test, ~modelr::rmse(model = .x, data = .y)),
    rmse_length_gaweeks = map2_dbl(model_length_gaweeks, test, ~modelr::rmse(model = .x, data = .y)),
    rmse_interactions = map2_dbl(model_interactions, test, ~modelr::rmse(model = .x, data = .y))
   )
```

```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse, color=model)) + 
  geom_violin() +   geom_boxplot(alpha = 0.5)+
  labs(title = 
  "Prediction Error Distributions across Models", 
       x = "Models", y = "RMSE") +
  theme(plot.title = element_text(hjust = 0.5))
```

According to the plot, `my_model` seems to be potentially the best model due to the fact that it has the lowest RSME, following with `interaction` model then `length_gaweeks` model. 




